{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019년 12월 4일 \n",
    "\n",
    "https://www.tensorflow.org/tutorials/keras/save_and_load"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.0.0'"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import os\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "tf.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = tf.keras.datasets.mnist.load_data()\n",
    "\n",
    "train_labels = train_labels\n",
    "test_labels = test_labels\n",
    "\n",
    "# 일반적인 기계학습 (2차원 - 행, 열 )\n",
    "train_images = train_images.reshape(-1, 28 * 28) / 255.0\n",
    "test_images = test_images.reshape(-1, 28 * 28) / 255.0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 정의 \n",
    "가중치를 저장하고 불러오는 예제를 위해 간단한 모델 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_5\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_13 (Dense)             (None, 512)               401920    \n",
      "_________________________________________________________________\n",
      "dropout_8 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_14 (Dense)             (None, 512)               262656    \n",
      "_________________________________________________________________\n",
      "dropout_9 (Dropout)          (None, 512)               0         \n",
      "_________________________________________________________________\n",
      "dense_15 (Dense)             (None, 10)                5130      \n",
      "=================================================================\n",
      "Total params: 669,706\n",
      "Trainable params: 669,706\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "# 간단한 Sequential 모델을 반환합니다\n",
    "def create_model():\n",
    "  model = tf.keras.models.Sequential([\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(512, activation='relu', input_shape=(784,)),\n",
    "    keras.layers.Dropout(0.2),\n",
    "    keras.layers.Dense(10, activation='softmax')\n",
    "  ])\n",
    "\n",
    "  model.compile(optimizer='adam',\n",
    "                loss='sparse_categorical_crossentropy',\n",
    "                # 원핫 인코딩 안해서 sparse_\n",
    "                metrics=['accuracy'])\n",
    "\n",
    "  return model\n",
    "\n",
    "\n",
    "# 모델 객체를 만듭니다\n",
    "model = create_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Checkpoint "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.callbacks.ModelCheckpoint"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.callbacks.ModelCheckpoint\n",
    "# save_best_only: True (가장 좋은 하이퍼파라미터일때 불러들일 수 있다.)\n",
    "# ModelCheckpoint는 시행착오용으로 쓴다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.callbacks.EarlyStopping"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tf.keras.callbacks.EarlyStopping"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- 파일 종류 \n",
    "text(눈으로 볼 수 있음), binary(눈으로 볼 수 없음)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"training_1/cp.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples, validate on 10000 samples\n",
      "Epoch 1/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.2143 - accuracy: 0.9344 ETA: 0s - loss: 0.2152 - accuracy: 0.93 - ETA: 0s - loss: 0.2149 - accura\n",
      "Epoch 00001: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 38s 638us/sample - loss: 0.2143 - accuracy: 0.9344 - val_loss: 0.1012 - val_accuracy: 0.9658\n",
      "Epoch 2/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.1053 - accuracy: 0.9675 ETA: 0s - loss: 0.1053 - accuracy: \n",
      "Epoch 00002: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 40s 662us/sample - loss: 0.1053 - accuracy: 0.9675 - val_loss: 0.0853 - val_accuracy: 0.9732\n",
      "Epoch 3/10\n",
      "59968/60000 [============================>.] - ETA: 0s - loss: 0.0795 - accuracy: 0.9751\n",
      "Epoch 00003: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 39s 653us/sample - loss: 0.0796 - accuracy: 0.9751 - val_loss: 0.0751 - val_accuracy: 0.9777\n",
      "Epoch 4/10\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.0629 - accuracy: 0.9796\n",
      "Epoch 00004: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 38s 629us/sample - loss: 0.0629 - accuracy: 0.9796 - val_loss: 0.0725 - val_accuracy: 0.9776\n",
      "Epoch 5/10\n",
      "59904/60000 [============================>.] - ETA: 0s - loss: 0.0573 - accuracy: 0.9822\n",
      "Epoch 00005: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 38s 641us/sample - loss: 0.0574 - accuracy: 0.9822 - val_loss: 0.0917 - val_accuracy: 0.9765\n",
      "Epoch 6/10\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.0498 - accuracy: 0.9842\n",
      "Epoch 00006: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 41s 677us/sample - loss: 0.0498 - accuracy: 0.9841 - val_loss: 0.0866 - val_accuracy: 0.9760\n",
      "Epoch 7/10\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.0475 - accuracy: 0.9852\n",
      "Epoch 00007: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 46s 764us/sample - loss: 0.0476 - accuracy: 0.9852 - val_loss: 0.0802 - val_accuracy: 0.9795\n",
      "Epoch 8/10\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.0412 - accuracy: 0.9875\n",
      "Epoch 00008: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 41s 679us/sample - loss: 0.0412 - accuracy: 0.9875 - val_loss: 0.0746 - val_accuracy: 0.9822\n",
      "Epoch 9/10\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.0417 - accuracy: 0.9870\n",
      "Epoch 00009: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 42s 694us/sample - loss: 0.0417 - accuracy: 0.9870 - val_loss: 0.0853 - val_accuracy: 0.9772\n",
      "Epoch 10/10\n",
      "59936/60000 [============================>.] - ETA: 0s - loss: 0.0356 - accuracy: 0.9883\n",
      "Epoch 00010: saving model to training_1/cp.ckpt\n",
      "60000/60000 [==============================] - 40s 663us/sample - loss: 0.0357 - accuracy: 0.9883 - val_loss: 0.0751 - val_accuracy: 0.9823\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x20355940978>"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 체크포인트 콜백 만들기 - 잘못되면 되돌아 갈 수 있는 것 \n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                 save_weights_only=True,\n",
    "                                                 verbose=1)\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels,  epochs = 2,\n",
    "          validation_data = (test_images,test_labels),\n",
    "          callbacks = [cp_callback])  # 훈련 단계에 콜백을 전달합니다\n",
    "\n",
    "# 옵티마이저의 상태를 저장하는 것과 관련되a어 경고가 발생할 수 있습니다.\n",
    "# 이 경고는 (그리고 이 노트북의 다른 비슷한 경고는) 이전 사용 방식을 권장하지 않기 위함이며 무시해도 좋습니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 2s - loss: 2.3628 - accuracy: 0.0975\n",
      "훈련되지 않은 모델의 정확도:  9.75%\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"훈련되지 않은 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 2s - loss: 0.0376 - accuracy: 0.9823\n",
      "복원된 모델의 정확도: 98.23%\n"
     ]
    }
   ],
   "source": [
    "model.load_weights(checkpoint_path)\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1204 14:27:34.802543 21096 callbacks.py:863] `period` argument is deprecated. Please use `save_freq` to specify the frequency in number of samples seen.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch 00001: saving model to training_2/cp-0001.ckpt\n",
      "\n",
      "Epoch 00002: saving model to training_2/cp-0002.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x2035830fa90>"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파일 이름에 에포크 번호를 포함시킵니다(`str.format` 포맷)\n",
    "checkpoint_path = \"training_2/cp-{epoch:04d}.ckpt\"\n",
    "checkpoint_dir = os.path.dirname(checkpoint_path)\n",
    "\n",
    "cp_callback = tf.keras.callbacks.ModelCheckpoint(\n",
    "    checkpoint_path, verbose=1, save_weights_only=True,\n",
    "    # period: 한 번째 에포크마다 가중치를 저장합니다\n",
    "    period=1)\n",
    "# period를 굳이 쓸 필요는 없다. (test용으로 쓰기 때문에 필요없다.)\n",
    "# save_best_model를 쓰는게 훨씬 낫다.\n",
    "\n",
    "model = create_model()\n",
    "model.save_weights(checkpoint_path.format(epoch=0))\n",
    "model.fit(train_images, train_labels,\n",
    "          epochs = 2, callbacks = [cp_callback],\n",
    "          validation_data = (test_images,test_labels),\n",
    "          verbose=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'training_2\\\\cp-0002.ckpt'"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "latest = tf.train.latest_checkpoint(checkpoint_dir)\n",
    "latest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 2s - loss: 0.0538 - accuracy: 0.9711\n",
      "복원된 모델의 정확도: 97.11%\n"
     ]
    }
   ],
   "source": [
    "# keras 버전에서만 불러들일 수 있다. \n",
    "# keras checkpoint는 테스트용이다. \n",
    "model = create_model()\n",
    "model.load_weights(latest)\n",
    "loss, acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "https://github.com/ysh329/deep-learning-model-convertor\n",
    "\n",
    "외부 파일을 이용해서 다른 모델에서도 쓸 수 있긴하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 모델 전체를 저장하기 \n",
    "- HDF5 파일로 저장하기 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install -q h5py pyyaml\n",
    "# 데이터를 관리하기 위해서 많이 썼다. \n",
    "# hierarchy: 계층적으로 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "W1204 14:40:36.599096 21096 util.py:144] Unresolved object in checkpoint: (root).optimizer.iter\n",
      "W1204 14:40:36.600096 21096 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_1\n",
      "W1204 14:40:36.601093 21096 util.py:144] Unresolved object in checkpoint: (root).optimizer.beta_2\n",
      "W1204 14:40:36.602094 21096 util.py:144] Unresolved object in checkpoint: (root).optimizer.decay\n",
      "W1204 14:40:36.603094 21096 util.py:144] Unresolved object in checkpoint: (root).optimizer.learning_rate\n",
      "W1204 14:40:36.604093 21096 util.py:152] A checkpoint was restored (e.g. tf.train.Checkpoint.restore or tf.keras.Model.load_weights) but not all checkpointed values were used. See above for specific issues. Use expect_partial() on the load status object, e.g. tf.train.Checkpoint.restore(...).expect_partial(), to silence these warnings, or use assert_consumed() to make the check explicit. See https://www.tensorflow.org/alpha/guide/checkpoints#loading_mechanics for details.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000/60000 [==============================] - 34s 568us/sample - loss: 0.2153 - accuracy: 0.9335\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 35s 591us/sample - loss: 0.1066 - accuracy: 0.9672\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 38s 638us/sample - loss: 0.0801 - accuracy: 0.9746\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 36s 600us/sample - loss: 0.0686 - accuracy: 0.9790- loss: 0.0683 - accuracy:  - ETA: 0s - loss: 0.0684 - \n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 38s 638us/sample - loss: 0.0589 - accuracy: 0.9811\n"
     ]
    }
   ],
   "source": [
    "model = create_model()\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)\n",
    "\n",
    "# 전체 모델을 HDF5 파일로 저장합니다\n",
    "model.save('my_model.h5')\n",
    "# model checkpoint \n",
    "# 이건 최종 모델만 저장할 수 있다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### save_weights "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 수동으로 가중치 저장하기 \n",
    "\n",
    "# 가중치를 저장합니다\n",
    "model.save_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "# 가중치를 복원합니다\n",
    "model = create_model()\n",
    "model.load_weights('./checkpoints/my_checkpoint')\n",
    "\n",
    "loss,acc = model.evaluate(test_images,  test_labels, verbose=2)\n",
    "print(\"복원된 모델의 정확도: {:5.2f}%\".format(100*acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save_weights('./checkpoints/my_checkpoint', save_format='h5') # tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "check point 저장 방식 \n",
    "- tensorflow: keras에서 충돌날 수 있다. \n",
    "- hdf5: 이 방식을 쓰는게 가장 좋다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras \n",
    "# keras/tensorflow 는 혼용해서 쓰면 안된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "nn = tf.keras.models.Sequential()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<bound method Network.save_weights of <tensorflow.python.keras.engine.sequential.Sequential object at 0x00000203782D7588>>"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nn.save_weights\n",
    "# hdf5로 저장할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import load_iris"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neural_network import MLPClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_iris()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp = MLPClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp.fit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.wrappers.scikit_learn import KerasClassifier\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "KerasClassifier\n",
    "# Encapsulation "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(64, input_shape=(4,), activation='relu'))\n",
    "    model.add(Dense(64, activation='relu'))\n",
    "    model.add(Dense(4, activation='softmax'))\n",
    "    \n",
    "    model.compile(loss='sparse_categorical_crossentropy', \n",
    "                 optimizer='adam',metrics=['accuracy'] \n",
    "                 )\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_k = KerasClassifier(create_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/5\n",
      "150/150 [==============================] - 0s 3ms/sample - loss: 1.2243 - accuracy: 0.3133\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 0s 127us/sample - loss: 1.0293 - accuracy: 0.3933\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 0s 87us/sample - loss: 0.9274 - accuracy: 0.6267\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8402 - accuracy: 0.6667\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.7647 - accuracy: 0.7133\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e69be28748>"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mlp_k.fit(data.data, data.target, epochs=5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- cross_val_score\n",
    "- gridSearchcv\n",
    "- pipeline\n",
    "등 다 쓸 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import cross_val_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 0s 4ms/sample - loss: 1.1989 - accuracy: 0.3481\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 133us/sample - loss: 0.9120 - accuracy: 0.6593\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 0.8614 - accuracy: 0.6593\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 104us/sample - loss: 0.7843 - accuracy: 0.7852\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 0.7094 - accuracy: 0.7407\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 17ms/sample - loss: 0.4784 - accuracy: 1.0000\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 1s 4ms/sample - loss: 1.9681 - accuracy: 0.3704\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 118us/sample - loss: 1.5325 - accuracy: 0.3704\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 1.2868 - accuracy: 0.3704\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 1.1099 - accuracy: 0.3704\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 0.9838 - accuracy: 0.4444\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 9ms/sample - loss: 1.2023 - accuracy: 0.7333\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 0s 3ms/sample - loss: 1.5015 - accuracy: 0.1037\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 133us/sample - loss: 1.1399 - accuracy: 0.3704\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 0.9574 - accuracy: 0.7852\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 104us/sample - loss: 0.8668 - accuracy: 0.6593\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 118us/sample - loss: 0.7992 - accuracy: 0.6370\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 9ms/sample - loss: 0.6596 - accuracy: 1.0000\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 0s 3ms/sample - loss: 1.6088 - accuracy: 0.2963\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 133us/sample - loss: 1.2148 - accuracy: 0.4074\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 1.0063 - accuracy: 0.4519\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 104us/sample - loss: 0.8687 - accuracy: 0.7037\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 0.7752 - accuracy: 0.7037\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 9ms/sample - loss: 0.9185 - accuracy: 0.3333\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 1s 4ms/sample - loss: 1.5913 - accuracy: 0.0963\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 104us/sample - loss: 1.3359 - accuracy: 0.2222\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 126us/sample - loss: 1.1583 - accuracy: 0.5630\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 126us/sample - loss: 1.0357 - accuracy: 0.7407\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 126us/sample - loss: 0.9377 - accuracy: 0.7407\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 12ms/sample - loss: 1.2448 - accuracy: 0.0000e+00\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 1s 4ms/sample - loss: 1.3777 - accuracy: 0.3704\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 118us/sample - loss: 1.1103 - accuracy: 0.3704\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 141us/sample - loss: 0.9660 - accuracy: 0.7259\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 141us/sample - loss: 0.8777 - accuracy: 0.7407\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 0.8028 - accuracy: 0.7407\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 10ms/sample - loss: 1.2072 - accuracy: 0.0000e+00\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 0s 3ms/sample - loss: 1.1650 - accuracy: 0.3259\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 141us/sample - loss: 0.9264 - accuracy: 0.7037\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 118us/sample - loss: 0.8291 - accuracy: 0.7037\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 126us/sample - loss: 0.7415 - accuracy: 0.7185\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 104us/sample - loss: 0.6798 - accuracy: 0.9333\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 9ms/sample - loss: 0.8004 - accuracy: 1.0000\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 1s 5ms/sample - loss: 1.1595 - accuracy: 0.3037\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 118us/sample - loss: 1.0325 - accuracy: 0.4148\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 0.9588 - accuracy: 0.6815\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 96us/sample - loss: 0.8931 - accuracy: 0.7333\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 118us/sample - loss: 0.8299 - accuracy: 0.7556\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 9ms/sample - loss: 0.8157 - accuracy: 0.8667\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 1s 4ms/sample - loss: 1.2818 - accuracy: 0.3704\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 111us/sample - loss: 1.0569 - accuracy: 0.6296\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 104us/sample - loss: 0.9171 - accuracy: 0.7556\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 148us/sample - loss: 0.8269 - accuracy: 0.7407\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 141us/sample - loss: 0.7505 - accuracy: 0.7407\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 11ms/sample - loss: 0.9558 - accuracy: 0.0000e+00\n",
      "Train on 135 samples\n",
      "Epoch 1/5\n",
      "135/135 [==============================] - 1s 9ms/sample - loss: 1.4567 - accuracy: 0.3111\n",
      "Epoch 2/5\n",
      "135/135 [==============================] - 0s 215us/sample - loss: 1.2113 - accuracy: 0.3926\n",
      "Epoch 3/5\n",
      "135/135 [==============================] - 0s 148us/sample - loss: 1.0369 - accuracy: 0.4074\n",
      "Epoch 4/5\n",
      "135/135 [==============================] - 0s 155us/sample - loss: 0.9059 - accuracy: 0.7333\n",
      "Epoch 5/5\n",
      "135/135 [==============================] - 0s 178us/sample - loss: 0.8143 - accuracy: 0.7407\n",
      "15/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 14ms/sample - loss: 0.8991 - accuracy: 0.1333\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([1.        , 0.73333335, 1.        , 0.33333334, 0.        ,\n",
       "       0.        , 1.        , 0.86666667, 0.        , 0.13333334])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cross_val_score(KerasClassifier(create_model,epochs=5), data.data, data.target, cv=10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 0s 40ms/sample - loss: 1.0920 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 0s 333us/sample - loss: 0.9709 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 0s 333us/sample - loss: 0.8557 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 0s 333us/sample - loss: 0.7484 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 0s 416us/sample - loss: 0.6498 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 0.5589 - accuracy: 1.0000\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 583us/sample - loss: 0.5604 - accuracy: 1.0000\n",
      "Train on 39 samples\n",
      "Epoch 1/5\n",
      "39/39 [==============================] - 1s 19ms/sample - loss: 1.8458 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - 0s 256us/sample - loss: 1.4703 - accuracy: 0.1026\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 1.1758 - accuracy: 0.4872\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - 0s 231us/sample - loss: 0.9440 - accuracy: 0.5641\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - 0s 205us/sample - loss: 0.7819 - accuracy: 0.9744\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.7799 - accuracy: 1.0000\n",
      "39/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 154us/sample - loss: 0.6082 - accuracy: 1.0000\n",
      "Train on 66 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 0s 7ms/sample - loss: 1.3081 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 167us/sample - loss: 1.0797 - accuracy: 0.6970\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 212us/sample - loss: 0.9175 - accuracy: 0.6970\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 151us/sample - loss: 0.7905 - accuracy: 0.6970\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 167us/sample - loss: 0.7020 - accuracy: 0.6970\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.4927 - accuracy: 0.0000e+00\n",
      "66/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 121us/sample - loss: 0.4712 - accuracy: 0.6970\n",
      "Train on 93 samples\n",
      "Epoch 1/5\n",
      "93/93 [==============================] - 1s 6ms/sample - loss: 1.4195 - accuracy: 0.3011\n",
      "Epoch 2/5\n",
      "93/93 [==============================] - 0s 140us/sample - loss: 1.1510 - accuracy: 0.5914\n",
      "Epoch 3/5\n",
      "93/93 [==============================] - 0s 161us/sample - loss: 1.0101 - accuracy: 0.5376\n",
      "Epoch 4/5\n",
      "93/93 [==============================] - 0s 161us/sample - loss: 0.9395 - accuracy: 0.5376\n",
      "Epoch 5/5\n",
      "93/93 [==============================] - 0s 140us/sample - loss: 0.8791 - accuracy: 0.5376\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.0288 - accuracy: 0.0333\n",
      "93/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 75us/sample - loss: 1.0066 - accuracy: 0.5484\n",
      "Train on 120 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.5931 - accuracy: 0.4000\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 0s 117us/sample - loss: 1.3190 - accuracy: 0.4167\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.1461 - accuracy: 0.4167\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 0s 125us/sample - loss: 1.0279 - accuracy: 0.4750\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 0s 108us/sample - loss: 0.9477 - accuracy: 0.4167\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 4ms/sample - loss: 1.2104 - accuracy: 0.0000e+00\n",
      "120/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 58us/sample - loss: 0.7997 - accuracy: 0.4750\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 1s 43ms/sample - loss: 1.6297 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 0s 333us/sample - loss: 1.5217 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 0s 333us/sample - loss: 1.4212 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 0s 250us/sample - loss: 1.3254 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 0s 333us/sample - loss: 1.2350 - accuracy: 0.7500\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 1.2567 - accuracy: 0.6667\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 500us/sample - loss: 1.1488 - accuracy: 1.0000\n",
      "Train on 39 samples\n",
      "Epoch 1/5\n",
      "39/39 [==============================] - 1s 19ms/sample - loss: 1.5860 - accuracy: 0.2308\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - 0s 333us/sample - loss: 1.2654 - accuracy: 0.2308\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 0.9903 - accuracy: 0.2308\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 0.7896 - accuracy: 0.9231\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 0.6503 - accuracy: 0.7692\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 21ms/sample - loss: 0.6334 - accuracy: 0.6667\n",
      "39/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 205us/sample - loss: 0.7785 - accuracy: 0.7692\n",
      "Train on 66 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 1s 10ms/sample - loss: 1.4096 - accuracy: 0.5303\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 257us/sample - loss: 1.0834 - accuracy: 0.5455\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 227us/sample - loss: 0.8591 - accuracy: 0.7727\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 212us/sample - loss: 0.6945 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 212us/sample - loss: 0.5815 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 0.5203 - accuracy: 1.0000\n",
      "66/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 167us/sample - loss: 0.5172 - accuracy: 1.0000\n",
      "Train on 93 samples\n",
      "Epoch 1/5\n",
      "93/93 [==============================] - 1s 7ms/sample - loss: 1.4103 - accuracy: 0.2473\n",
      "Epoch 2/5\n",
      "93/93 [==============================] - 0s 150us/sample - loss: 1.1558 - accuracy: 0.2903\n",
      "Epoch 3/5\n",
      "93/93 [==============================] - 0s 150us/sample - loss: 1.0559 - accuracy: 0.4301\n",
      "Epoch 4/5\n",
      "93/93 [==============================] - 0s 183us/sample - loss: 1.0165 - accuracy: 0.4409\n",
      "Epoch 5/5\n",
      "93/93 [==============================] - 0s 150us/sample - loss: 0.9680 - accuracy: 0.5699\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 5ms/sample - loss: 0.8311 - accuracy: 0.8667\n",
      "93/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 97us/sample - loss: 1.0850 - accuracy: 0.7204\n",
      "Train on 120 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 7ms/sample - loss: 1.6842 - accuracy: 0.2500\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 0s 158us/sample - loss: 1.2735 - accuracy: 0.3417\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 1.0705 - accuracy: 0.4250\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9828 - accuracy: 0.4167\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9247 - accuracy: 0.4167\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 1.1278 - accuracy: 0.1000\n",
      "120/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 100us/sample - loss: 0.7653 - accuracy: 0.4417\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 1s 55ms/sample - loss: 1.3352 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 0s 417us/sample - loss: 1.2099 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 0s 500us/sample - loss: 1.0953 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 0s 416us/sample - loss: 0.9885 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 0s 417us/sample - loss: 0.8919 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 1.5965 - accuracy: 0.0000e+00\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 416us/sample - loss: 0.8059 - accuracy: 1.0000\n",
      "Train on 39 samples\n",
      "Epoch 1/5\n",
      "39/39 [==============================] - 1s 15ms/sample - loss: 1.4156 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - 0s 410us/sample - loss: 1.0951 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - 0s 308us/sample - loss: 0.8206 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - 0s 307us/sample - loss: 0.6020 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - 0s 308us/sample - loss: 0.4383 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 3.0338 - accuracy: 0.0000e+00\n",
      "39/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 205us/sample - loss: 0.3273 - accuracy: 1.0000\n",
      "Train on 66 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 1s 9ms/sample - loss: 1.3870 - accuracy: 0.0152\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 257us/sample - loss: 1.1222 - accuracy: 0.6515\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 212us/sample - loss: 0.9380 - accuracy: 0.7576\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 212us/sample - loss: 0.7958 - accuracy: 0.7576\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 227us/sample - loss: 0.7036 - accuracy: 0.7576\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 1s 23ms/sample - loss: 1.5963 - accuracy: 0.0000e+00\n",
      "66/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 136us/sample - loss: 1.0995 - accuracy: 0.7576\n",
      "Train on 93 samples\n",
      "Epoch 1/5\n",
      "93/93 [==============================] - 1s 6ms/sample - loss: 0.9435 - accuracy: 0.7849\n",
      "Epoch 2/5\n",
      "93/93 [==============================] - 0s 183us/sample - loss: 0.8270 - accuracy: 0.7849\n",
      "Epoch 3/5\n",
      "93/93 [==============================] - 0s 183us/sample - loss: 0.7357 - accuracy: 0.7849\n",
      "Epoch 4/5\n",
      "93/93 [==============================] - 0s 161us/sample - loss: 0.6549 - accuracy: 0.7849\n",
      "Epoch 5/5\n",
      "93/93 [==============================] - 0s 150us/sample - loss: 0.5941 - accuracy: 0.7849\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 1.1855 - accuracy: 0.0000e+00\n",
      "93/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 118us/sample - loss: 0.5779 - accuracy: 0.7849\n",
      "Train on 120 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 5ms/sample - loss: 1.2792 - accuracy: 0.4167\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 0s 183us/sample - loss: 1.0381 - accuracy: 0.4167\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.9085 - accuracy: 0.8250\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.8054 - accuracy: 0.8333\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7159 - accuracy: 0.8333\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.8358 - accuracy: 0.0000e+00\n",
      "120/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 83us/sample - loss: 0.5162 - accuracy: 0.8333\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 1s 52ms/sample - loss: 2.0813 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 0s 500us/sample - loss: 1.8560 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 0s 500us/sample - loss: 1.6407 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 0s 583us/sample - loss: 1.4379 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 0s 583us/sample - loss: 1.2501 - accuracy: 0.0000e+00\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 2.2526 - accuracy: 0.0000e+00\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 500us/sample - loss: 1.0796 - accuracy: 0.3333\n",
      "Train on 39 samples\n",
      "Epoch 1/5\n",
      "39/39 [==============================] - 1s 16ms/sample - loss: 0.8224 - accuracy: 1.0000\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 0.5960 - accuracy: 1.0000\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 0.4232 - accuracy: 1.0000\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 0.2956 - accuracy: 1.0000\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - 0s 282us/sample - loss: 0.2051 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 3.6696 - accuracy: 0.0000e+00\n",
      "39/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 179us/sample - loss: 0.1440 - accuracy: 1.0000\n",
      "Train on 66 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 1s 13ms/sample - loss: 1.6258 - accuracy: 0.0303\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 227us/sample - loss: 1.2330 - accuracy: 0.7576\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 197us/sample - loss: 0.9624 - accuracy: 0.7576\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 227us/sample - loss: 0.7741 - accuracy: 0.7576\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 257us/sample - loss: 0.6439 - accuracy: 0.7576\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 2.5358 - accuracy: 0.0000e+00\n",
      "66/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 121us/sample - loss: 1.1478 - accuracy: 0.7576\n",
      "Train on 93 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 7ms/sample - loss: 1.3481 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "93/93 [==============================] - 0s 204us/sample - loss: 1.1162 - accuracy: 0.4194\n",
      "Epoch 3/5\n",
      "93/93 [==============================] - 0s 150us/sample - loss: 0.9628 - accuracy: 0.4301\n",
      "Epoch 4/5\n",
      "93/93 [==============================] - 0s 161us/sample - loss: 0.8573 - accuracy: 0.4839\n",
      "Epoch 5/5\n",
      "93/93 [==============================] - 0s 140us/sample - loss: 0.7769 - accuracy: 0.9570\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 2.4287 - accuracy: 0.3333\n",
      "93/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 107us/sample - loss: 0.7965 - accuracy: 0.9677\n",
      "Train on 120 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 9ms/sample - loss: 1.2865 - accuracy: 0.3083\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.1016 - accuracy: 0.5750\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.9610 - accuracy: 0.7667\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 0.8586 - accuracy: 0.8750\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 0s 142us/sample - loss: 0.7826 - accuracy: 0.8667\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 0.7615 - accuracy: 0.9000\n",
      "120/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 75us/sample - loss: 0.7234 - accuracy: 0.8833\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 12 samples\n",
      "Epoch 1/5\n",
      "12/12 [==============================] - 1s 50ms/sample - loss: 1.7750 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "12/12 [==============================] - 0s 417us/sample - loss: 1.6005 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "12/12 [==============================] - 0s 583us/sample - loss: 1.4390 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "12/12 [==============================] - 0s 583us/sample - loss: 1.2882 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "12/12 [==============================] - 0s 417us/sample - loss: 1.1483 - accuracy: 0.0000e+00\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 0.5336 - accuracy: 1.0000\n",
      "12/1 [========================================================================================================================================================================================================================================================================================================================================================================] - 0s 416us/sample - loss: 1.0196 - accuracy: 0.0000e+00\n",
      "Train on 39 samples\n",
      "Epoch 1/5\n",
      "39/39 [==============================] - 1s 22ms/sample - loss: 1.9843 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "39/39 [==============================] - 0s 384us/sample - loss: 1.6762 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "39/39 [==============================] - 0s 308us/sample - loss: 1.4053 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "39/39 [==============================] - 0s 359us/sample - loss: 1.1741 - accuracy: 0.0000e+00\n",
      "Epoch 5/5\n",
      "39/39 [==============================] - 0s 333us/sample - loss: 0.9716 - accuracy: 1.0000\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 7ms/sample - loss: 1.3033 - accuracy: 0.0000e+00\n",
      "39/1 [==================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 179us/sample - loss: 0.8164 - accuracy: 1.0000\n",
      "Train on 66 samples\n",
      "Epoch 1/5\n",
      "66/66 [==============================] - 1s 10ms/sample - loss: 1.0305 - accuracy: 0.7576\n",
      "Epoch 2/5\n",
      "66/66 [==============================] - 0s 273us/sample - loss: 0.8408 - accuracy: 0.7576\n",
      "Epoch 3/5\n",
      "66/66 [==============================] - 0s 197us/sample - loss: 0.7139 - accuracy: 0.7576\n",
      "Epoch 4/5\n",
      "66/66 [==============================] - 0s 212us/sample - loss: 0.6258 - accuracy: 0.7576\n",
      "Epoch 5/5\n",
      "66/66 [==============================] - 0s 212us/sample - loss: 0.5609 - accuracy: 0.7576\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 4.1116 - accuracy: 0.0000e+00\n",
      "66/1 [============================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 167us/sample - loss: 0.9712 - accuracy: 0.7576\n",
      "Train on 93 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "93/93 [==============================] - 1s 7ms/sample - loss: 3.1136 - accuracy: 0.0000e+00\n",
      "Epoch 2/5\n",
      "93/93 [==============================] - 0s 236us/sample - loss: 2.3884 - accuracy: 0.0000e+00\n",
      "Epoch 3/5\n",
      "93/93 [==============================] - 0s 204us/sample - loss: 1.8268 - accuracy: 0.0000e+00\n",
      "Epoch 4/5\n",
      "93/93 [==============================] - 0s 150us/sample - loss: 1.4318 - accuracy: 0.2903\n",
      "Epoch 5/5\n",
      "93/93 [==============================] - 0s 140us/sample - loss: 1.1547 - accuracy: 0.4624\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 9ms/sample - loss: 2.5649 - accuracy: 0.0000e+00\n",
      "93/1 [======================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 140us/sample - loss: 0.8097 - accuracy: 0.4624\n",
      "Train on 120 samples\n",
      "Epoch 1/5\n",
      "120/120 [==============================] - 1s 6ms/sample - loss: 1.8241 - accuracy: 0.1667\n",
      "Epoch 2/5\n",
      "120/120 [==============================] - 0s 167us/sample - loss: 1.4547 - accuracy: 0.1667\n",
      "Epoch 3/5\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 1.1917 - accuracy: 0.4500\n",
      "Epoch 4/5\n",
      "120/120 [==============================] - 0s 133us/sample - loss: 1.0169 - accuracy: 0.7333\n",
      "Epoch 5/5\n",
      "120/120 [==============================] - 0s 150us/sample - loss: 0.8979 - accuracy: 0.8333\n",
      "30/1 [====================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 6ms/sample - loss: 1.3496 - accuracy: 0.0000e+00\n",
      "120/1 [================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================================] - 0s 108us/sample - loss: 1.0355 - accuracy: 0.8333\n"
     ]
    }
   ],
   "source": [
    "train_size, train_score, test_score = learning_curve(KerasClassifier(create_model,epochs=5), data.data, data.target, cv=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sklearn_evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1e6b4575e10>"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "sklearn_evaluation.plot.learning_curve(train_score, test_score, train_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "요동치는 것은 데이터수가 부족하다는 것 \n",
    "\n",
    "learning curve "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "std = StandardScaler()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe = Pipeline([('scaler', StandardScaler()), ('keras', KerasClassifier(create_model,epochs=5))])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 150 samples\n",
      "Epoch 1/5\n",
      "150/150 [==============================] - 1s 3ms/sample - loss: 1.3315 - accuracy: 0.4200\n",
      "Epoch 2/5\n",
      "150/150 [==============================] - 0s 120us/sample - loss: 1.1513 - accuracy: 0.6667\n",
      "Epoch 3/5\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.9919 - accuracy: 0.7800\n",
      "Epoch 4/5\n",
      "150/150 [==============================] - 0s 93us/sample - loss: 0.8625 - accuracy: 0.7867\n",
      "Epoch 5/5\n",
      "150/150 [==============================] - 0s 100us/sample - loss: 0.7558 - accuracy: 0.7933\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "Pipeline(memory=None,\n",
       "         steps=[('scaler',\n",
       "                 StandardScaler(copy=True, with_mean=True, with_std=True)),\n",
       "                ('keras',\n",
       "                 <tensorflow.python.keras.wrappers.scikit_learn.KerasClassifier object at 0x000001E6B2B3F940>)],\n",
       "         verbose=False)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pipe.fit(data.data, data.target)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### keras & scikit 연동하기 \n",
    "\n",
    "재활용할 때 좋다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.0.0\n"
     ]
    }
   ],
   "source": [
    "import pathlib\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "\n",
    "print(tf.__version__)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "기계학습: 자기가 룰 찾아내는 것 (사람의 시행착오) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  Convolution Neural Network\n",
    "- https://www.tensorflow.org/tutorials/images/cnn\n",
    "- 합성공 신경망 \n",
    "\n",
    "- depth가 필요하므로 다 3차원으로 집어넣는다. \n",
    "\n",
    "- nlp, 신호처리에도 쓰였다. 그 때는 1차원(Conv1D)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "특징 찾아내는 컨볼루션 \n",
    "- python: conv-forword \n",
    "- tensorflow: tf.nn.conv2d \n",
    "- keras: Conv2D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "vertical filter \n",
    "sobel filter (1 ,2 ,1 ,0 ,0, 0, -1, -2, -1)\n",
    "scharr filter (3, 10, 3, 0, 0, 0 , -3, -10 , -3) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "\n",
    "from tensorflow.keras import datasets, layers, models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "(train_images, train_labels), (test_images, test_labels) = datasets.mnist.load_data()\n",
    "\n",
    "# cnn 은 depth를 하나 더 만들어줘서 3차원으로 만든다. \n",
    "train_images = train_images.reshape((60000, 28, 28, 1))\n",
    "test_images = test_images.reshape((10000, 28, 28, 1))\n",
    "\n",
    "# 픽셀 값을 0~1 사이로 정규화합니다.\n",
    "train_images, test_images = train_images / 255.0, test_images / 255.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = models.Sequential()\n",
    "# 3차원임으로 input_shape=(28,28,1)이다. \n",
    "# 32개의 특성을 (3,3) 커널 형태\n",
    "model.add(layers.Conv2D(32, (3, 3), activation='relu', input_shape=(28, 28, 1)))\n",
    "# 가장 큰 값 뽑는 것 (특성을 줄였다.)\n",
    "# maxpooling은 속도도 빨라지고, overfitting도 방지해준다. \n",
    "# 컴퓨터 성능이 좋으면 안해줘도 되긴 한다. (특성값을 잃는 것이므로)\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "# 64개의 특성으로 (3,3)\n",
    "# relu를 쓰는 이유는 얘도 학습을 할 것이기 때문이다. \n",
    "# relu쓰는 이유는 overfitting 막기 위해서 \n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))\n",
    "model.add(layers.MaxPooling2D((2, 2)))\n",
    "model.add(layers.Conv2D(64, (3, 3), activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "=================================================================\n",
      "Total params: 55,744\n",
      "Trainable params: 55,744\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 전통적인 머신러닝 방법 - 1차원 (flatten)\n",
    "# 특징을 학습한다. \n",
    "model.add(layers.Flatten())\n",
    "# 64로 하는 이유는 Conv2D 64로 끝났기 때문이다? 아니다.\n",
    "# 32로 바궈서 dense를 돌려도 돌아간다. \n",
    "# maxpooling 안하고 dense 안맞춰도 학습이 된다. \n",
    "# 사실상 성능이 크게 달라지지 않는다. \n",
    "# maxpooling은 속도도 빨라지고, overfitting도 방지해준다. \n",
    "model.add(layers.Dense(64, activation='relu'))\n",
    "# kernel_regularizer (l1 (|x|+|y|), l2 (x**2+y**2))\n",
    "model.add(layers.Dense(10, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_90\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "conv2d (Conv2D)              (None, 26, 26, 32)        320       \n",
      "_________________________________________________________________\n",
      "max_pooling2d (MaxPooling2D) (None, 13, 13, 32)        0         \n",
      "_________________________________________________________________\n",
      "conv2d_1 (Conv2D)            (None, 11, 11, 64)        18496     \n",
      "_________________________________________________________________\n",
      "max_pooling2d_1 (MaxPooling2 (None, 5, 5, 64)          0         \n",
      "_________________________________________________________________\n",
      "conv2d_2 (Conv2D)            (None, 3, 3, 64)          36928     \n",
      "_________________________________________________________________\n",
      "flatten (Flatten)            (None, 576)               0         \n",
      "_________________________________________________________________\n",
      "dense_270 (Dense)            (None, 64)                36928     \n",
      "_________________________________________________________________\n",
      "dense_271 (Dense)            (None, 10)                650       \n",
      "=================================================================\n",
      "Total params: 93,322\n",
      "Trainable params: 93,322\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 60000 samples\n",
      "Epoch 1/5\n",
      "60000/60000 [==============================] - 127s 2ms/sample - loss: 0.1477 - accuracy: 0.9537\n",
      "Epoch 2/5\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.0472 - accuracy: 0.9853\n",
      "Epoch 3/5\n",
      "60000/60000 [==============================] - 112s 2ms/sample - loss: 0.0342 - accuracy: 0.9891\n",
      "Epoch 4/5\n",
      "60000/60000 [==============================] - 115s 2ms/sample - loss: 0.0249 - accuracy: 0.9922\n",
      "Epoch 5/5\n",
      "60000/60000 [==============================] - 112s 2ms/sample - loss: 0.0204 - accuracy: 0.9936\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x1e6b1e01160>"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.compile(optimizer='adam', loss ='sparse_categorical_crossentropy',\n",
    "             metrics=['accuracy'])\n",
    "\n",
    "model.fit(train_images, train_labels, epochs=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "10000/1 - 5s - loss: 0.0167 - accuracy: 0.9908\n"
     ]
    }
   ],
   "source": [
    "test_loss, test_acc = model.evaluate(test_images,  test_labels, verbose=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9908\n"
     ]
    }
   ],
   "source": [
    "print(test_acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "roc \n",
    "- x축: data \n",
    "- y축: 성능"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- No Free Lunch \n",
    "\n",
    "성능이 좋지만, 과적합되기가 쉽다. \n",
    "- layer\n",
    "- node\n",
    "- epoch\n",
    "\n",
    "**[overfitting 막는 법]**\n",
    "\n",
    "**layers 에서 패널티를 줘서 과적합을 막을 수 있다.**\n",
    "- penalty, regularizer\n",
    "- l1\n",
    "- l2 \n",
    "- l1 & l2 두개를 쓸 수도 있다.\n",
    "\n",
    "kernel_regularizer (l1 (|x|+|y|), l2 (x**2+y**2))\n",
    "\n",
    "**cross_validation**\n",
    "- 확인하는 용도로 쓴다. \n",
    "- 데이터가 작을 때-차원의 저주로 오버피팅이 더 잘 난다. \n",
    "- 하지만 시간이 오래 걸리고, 비용이 많이 나오는 단점이 있다. \n",
    "\n",
    "**dropout** \n",
    "layer 뒤에 추가 가능.\n",
    "activation 뒤에 추가 가능.\n",
    "0.2 (20%)를 랜덤으로 빼버린다는 것.\n",
    "학습속도가 느리다. \n",
    "\n",
    "matplotlib에서 (state machine) - 앞에 있는 가장 가까운거 붙어서 하는 것 -> tf.keras.layers.Dropout(0.2) (앞에 Dense 붙어서 실행)\n",
    "\n",
    "**Early stopping**\n",
    "\n",
    "**Ensemble**\n",
    "- bagging <br>\n",
    "random boostrap 방법으로 샘플을 여러 번 뽑아 각 모델을 학습시켜 결과를 집계하는 방식이다.\n",
    "- boosting <br>\n",
    "성능 안좋은 것에 가중치줘서 학습시키는 것 \n",
    "- stacking <br>\n",
    "A 알고리즘, B 알고리즘, C 알고리즘을 또 학습시켜서 나온결과로 또 학습시키는 것이다. 하지만 단점으로 시간, 비용이 많이 필요하다. \n",
    "\n",
    "\n",
    "- 데이터를 늘린다. \n",
    "- 모델을 간단히 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Padding \n",
    "유효 합성곱(Valid convolutions): 패딩이 없는것 \n",
    "동일 합성곱(Same convolutions): 패딩을 한 뒤 결과 이미지의 크기가 기존 이미지와 동일\n",
    "p = (f-1)/2 "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 2019년 12월 5일"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. train slow\n",
    "\n",
    "2. better performance \n",
    "\n",
    "overfitting 과 underfitting을 보려면 learning curve 그래프를 확인해야한다. \n",
    "\n",
    "[LOC] \n",
    "x: epoch or data(keras 자체로는 그리기 힘들다, 따라서 sklearn이용해서 그린다.)\n",
    "\n",
    "y: loss(작을수록 좋다.) or 정확도(클수록 좋다.) \n",
    "\n",
    "\n",
    "- underfitting: 모델을 다시 만드는게 좋다. \n",
    "- overfitting: validation이 학습될수록 올라간다. \n",
    "    - 데이터를 늘린다. \n",
    "    - 모델을 간단히 한다. \n",
    "    - feature selection (차원 축소) \n",
    "    - deeplearning: layer, node 줄인다. (dropout)\n",
    "\n",
    "\n",
    "성능이 비슷하면 '오컴의 면도날'로 간단한 모델을 선택한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## keras/tensor\n",
    "\n",
    "서로 연동이 안된다. 따라서 tf.keras 가져와야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf \n",
    "from tensorflow.keras.datasets import cifar10\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Dropout, Activation, Flatten\n",
    "from tensorflow.keras.layers import Conv2D, MaxPooling2D\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 함수로 만들어서 넘기는 것이 좋다. \n",
    "batch_size = 32\n",
    "epochs = 1\n",
    "data_augmentation = True\n",
    "num_predictions = 20\n",
    "save_dir = os.path.join(os.getcwd(), 'saved_models')\n",
    "model_name = 'keras_cifar10_trained_model.h5'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x_train shape: (50000, 32, 32, 3)\n",
      "50000 train samples\n",
      "10000 test samples\n"
     ]
    }
   ],
   "source": [
    "# The data, split between train and test sets:\n",
    "(x_train, y_train), (x_test, y_test) = cifar10.load_data()\n",
    "print('x_train shape:', x_train.shape)\n",
    "print(x_train.shape[0], 'train samples')\n",
    "print(x_test.shape[0], 'test samples')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.image.AxesImage at 0x2d0901d0048>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.imshow(x_train[3])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow import keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.utils import to_categorical\n",
    "# sparse 빼고 쓸때 to_categorial 를 쓴다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Convert class vectors to binary class matrices.\n",
    "num_classes = 10\n",
    "y_train = keras.utils.to_categorical(y_train, num_classes)\n",
    "y_test = keras.utils.to_categorical(y_test, num_classes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- ImageDataGenerator (numpy -> tensor로 바꿔준다.)  \n",
    "- Image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tensorflow.keras는 float32가 기본 데이터 타입이다. \n",
    "# (opencv도 내부적으로 float32인데, opencv는 float32만 된다.)\n",
    "\n",
    "x_train = x_train.astype('float32')\n",
    "x_test = x_test.astype('float32')\n",
    "x_train /= 255\n",
    "x_test /= 255"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 32, 32, 3)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape\n",
    "# 3차원이면 너무 느려서 색상을 날려서 사용하기도 한다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Padding \n",
    "\n",
    "유효 합성곱(Valid convolutions): 패딩이 없는것 (stride 때문에 못갈 경우 멈추도록 도와주는 것)\n",
    "\n",
    "동일 합성곱(Same convolutions): 패딩을 한 뒤 결과 이미지의 크기가 기존 이미지와 동일 (strdie 때문에 못갈경우 뒤에 패딩을 추가) \n",
    "\n",
    "p = (f-1)/2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# correlation : 반전 안시키는 것\n",
    "# convolution : flip 해서 반전시키고 학습시키는 것 \n",
    "# 하지만 둘이 영상에서는 차이가 없어서 그냥 반전안시키고 cnn 쓴다. \n",
    "model = Sequential()\n",
    "model.add(Conv2D(32,(3,3), padding='same',\n",
    "                input_shape=x_train.shape[1:]))\n",
    "model.add(Activation('relu')) # relu안쓰면 과적합이 일어난다. \n",
    "model.add(Conv2D(32, (3,3)))\n",
    "model.add(Activation('relu'))\n",
    "# 요즘에 잘 안쓴다. (Stride로 대체시킨다.)\n",
    "# 처음 논문에서 maxpooling 쓰고 다음 모델에서 안쓰고 했기 때문에 이렇게 쓴다. \n",
    "model.add(MaxPooling2D(pool_size=(2,2)))\n",
    "# model.add(Dropout(0.25))\n",
    "\n",
    "# 0보다 작은걸 (1/100)x : leaky relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Conv2D(64, (3, 3), padding='same'))\n",
    "# relu를 sigmoid로 바꿨을 때 loss가 변하지 않는다. \n",
    "# loss값이 업데이트가 안될 경우 학습이 잘 안되는 것이다. \n",
    "model.add(Activation('relu'))\n",
    "model.add(Conv2D(64, (3, 3)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 2)))\n",
    "# model.add(Dropout(0.25))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.add(Flatten())\n",
    "model.add(Dense(128))\n",
    "model.add(Activation('relu'))\n",
    "# model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 남에것 갖다가 쓰는것 \n",
    "opt = keras.optimizers.RMSprop(learning_rate=0.0001, decay=1e-6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to_categorial: sparse 필요 없다.\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=opt,\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function tensorflow.python.ops.gen_nn_ops.relu(features, name=None)>"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# neural_network\n",
    "# 객체를 보통 가져온다. \n",
    "tf.nn.relu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 50000 samples, validate on 10000 samples\n",
      "38592/50000 [======================>.......] - ETA: 1:54 - loss: 2.3171 - accuracy: 0.0989"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-17-02317d6763cc>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      3\u001b[0m               \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      4\u001b[0m               \u001b[0mvalidation_data\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_test\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 5\u001b[1;33m               shuffle=True)\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, max_queue_size, workers, use_multiprocessing, **kwargs)\u001b[0m\n\u001b[0;32m    726\u001b[0m         \u001b[0mmax_queue_size\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mmax_queue_size\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    727\u001b[0m         \u001b[0mworkers\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mworkers\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 728\u001b[1;33m         use_multiprocessing=use_multiprocessing)\n\u001b[0m\u001b[0;32m    729\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    730\u001b[0m   def evaluate(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, model, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, validation_freq, **kwargs)\u001b[0m\n\u001b[0;32m    322\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    323\u001b[0m                 \u001b[0mtraining_context\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mtraining_context\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 324\u001b[1;33m                 total_epochs=epochs)\n\u001b[0m\u001b[0;32m    325\u001b[0m             \u001b[0mcbks\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmake_logs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mepoch_logs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtraining_result\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mModeKeys\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTRAIN\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    326\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2.py\u001b[0m in \u001b[0;36mrun_one_epoch\u001b[1;34m(model, iterator, execution_function, dataset_size, batch_size, strategy, steps_per_epoch, num_samples, mode, training_context, total_epochs)\u001b[0m\n\u001b[0;32m    121\u001b[0m         step=step, mode=mode, size=current_batch_size) as batch_logs:\n\u001b[0;32m    122\u001b[0m       \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 123\u001b[1;33m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    124\u001b[0m       \u001b[1;32mexcept\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mStopIteration\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0merrors\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mOutOfRangeError\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    125\u001b[0m         \u001b[1;31m# TODO(kaftan): File bug about tf function and errors.OutOfRangeError?\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mexecution_function\u001b[1;34m(input_fn)\u001b[0m\n\u001b[0;32m     84\u001b[0m     \u001b[1;31m# `numpy` translates Tensors to values in Eager mode.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     85\u001b[0m     return nest.map_structure(_non_none_constant_value,\n\u001b[1;32m---> 86\u001b[1;33m                               distributed_function(input_fn))\n\u001b[0m\u001b[0;32m     87\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     88\u001b[0m   \u001b[1;32mreturn\u001b[0m \u001b[0mexecution_function\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    455\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    456\u001b[0m     \u001b[0mtracing_count\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 457\u001b[1;33m     \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    458\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mtracing_count\u001b[0m \u001b[1;33m==\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_get_tracing_count\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    459\u001b[0m       \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_call_counter\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcalled_without_tracing\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\def_function.py\u001b[0m in \u001b[0;36m_call\u001b[1;34m(self, *args, **kwds)\u001b[0m\n\u001b[0;32m    485\u001b[0m       \u001b[1;31m# In this case we have created variables on the first call, so we run the\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    486\u001b[0m       \u001b[1;31m# defunned version which is guaranteed to never create variables.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 487\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateless_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=not-callable\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    488\u001b[0m     \u001b[1;32melif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_stateful_fn\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    489\u001b[0m       \u001b[1;31m# Release the lock early so that multiple threads can perform the call\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m   1821\u001b[0m     \u001b[1;34m\"\"\"Calls a graph function specialized to the inputs.\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1822\u001b[0m     \u001b[0mgraph_function\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_maybe_define_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1823\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgraph_function\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_filtered_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# pylint: disable=protected-access\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1824\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1825\u001b[0m   \u001b[1;33m@\u001b[0m\u001b[0mproperty\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_filtered_call\u001b[1;34m(self, args, kwargs)\u001b[0m\n\u001b[0;32m   1139\u001b[0m          if isinstance(t, (ops.Tensor,\n\u001b[0;32m   1140\u001b[0m                            resource_variable_ops.BaseResourceVariable))),\n\u001b[1;32m-> 1141\u001b[1;33m         self.captured_inputs)\n\u001b[0m\u001b[0;32m   1142\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1143\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_call_flat\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcaptured_inputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcancellation_manager\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36m_call_flat\u001b[1;34m(self, args, captured_inputs, cancellation_manager)\u001b[0m\n\u001b[0;32m   1222\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mexecuting_eagerly\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1223\u001b[0m       flat_outputs = forward_function.call(\n\u001b[1;32m-> 1224\u001b[1;33m           ctx, args, cancellation_manager=cancellation_manager)\n\u001b[0m\u001b[0;32m   1225\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1226\u001b[0m       \u001b[0mgradient_name\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_delayed_rewrite_functions\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mregister\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\function.py\u001b[0m in \u001b[0;36mcall\u001b[1;34m(self, ctx, args, cancellation_manager)\u001b[0m\n\u001b[0;32m    509\u001b[0m               \u001b[0minputs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    510\u001b[0m               \u001b[0mattrs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;34m\"executor_type\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mexecutor_type\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"config_proto\"\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 511\u001b[1;33m               ctx=ctx)\n\u001b[0m\u001b[0;32m    512\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    513\u001b[0m           outputs = execute.execute_with_cancellation(\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\eager\\execute.py\u001b[0m in \u001b[0;36mquick_execute\u001b[1;34m(op_name, num_outputs, inputs, attrs, ctx, name)\u001b[0m\n\u001b[0;32m     59\u001b[0m     tensors = pywrap_tensorflow.TFE_Py_Execute(ctx._handle, device_name,\n\u001b[0;32m     60\u001b[0m                                                \u001b[0mop_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0minputs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mattrs\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 61\u001b[1;33m                                                num_outputs)\n\u001b[0m\u001b[0;32m     62\u001b[0m   \u001b[1;32mexcept\u001b[0m \u001b[0mcore\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_NotOkStatusException\u001b[0m \u001b[1;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     63\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mname\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train, y_train,\n",
    "              batch_size=batch_size,\n",
    "              epochs=epochs,\n",
    "              validation_data=(x_test, y_test),\n",
    "              shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "# load_image: PIL -> image.to_array()\n",
    "\n",
    "datagen = ImageDataGenerator(\n",
    "        featurewise_center=False,  # set input mean to 0 over the dataset\n",
    "        samplewise_center=False,  # set each sample mean to 0\n",
    "        featurewise_std_normalization=False,  # divide inputs by std of the dataset\n",
    "        samplewise_std_normalization=False,  # divide each input by its std\n",
    "        zca_whitening=False,  # apply ZCA whitening\n",
    "        zca_epsilon=1e-06,  # epsilon for ZCA whitening\n",
    "        rotation_range=0,  # randomly rotate images in the range (degrees, 0 to 180)\n",
    "        # randomly shift images horizontally (fraction of total width)\n",
    "        width_shift_range=0.1,\n",
    "        # randomly shift images vertically (fraction of total height)\n",
    "        height_shift_range=0.1,\n",
    "        shear_range=0.,  # set range for random shear\n",
    "        zoom_range=0.,  # set range for random zoom\n",
    "        channel_shift_range=0.,  # set range for random channel shifts\n",
    "        # set mode for filling points outside the input boundaries\n",
    "        fill_mode='nearest',\n",
    "        cval=0.,  # value used for fill_mode = \"constant\"\n",
    "        horizontal_flip=True,  # randomly flip images\n",
    "        vertical_flip=False,  # randomly flip images\n",
    "        # set rescaling factor (applied before any other transformation)\n",
    "        rescale=None,\n",
    "        # set function that will be applied on each input\n",
    "        preprocessing_function=None,\n",
    "        # image data format, either \"channels_first\" or \"channels_last\"\n",
    "        data_format=None,\n",
    "        # fraction of images reserved for validation (strictly between 0 and 1)\n",
    "        validation_split=0.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featurewise_center': False,\n",
       " 'samplewise_center': False,\n",
       " 'featurewise_std_normalization': False,\n",
       " 'samplewise_std_normalization': False,\n",
       " 'zca_whitening': False,\n",
       " 'zca_epsilon': 1e-06,\n",
       " 'rotation_range': 0,\n",
       " 'width_shift_range': 0.1,\n",
       " 'height_shift_range': 0.1,\n",
       " 'shear_range': 0.0,\n",
       " 'zoom_range': [1.0, 1.0],\n",
       " 'channel_shift_range': 0.0,\n",
       " 'fill_mode': 'nearest',\n",
       " 'cval': 0.0,\n",
       " 'horizontal_flip': True,\n",
       " 'vertical_flip': False,\n",
       " 'rescale': None,\n",
       " 'preprocessing_function': None,\n",
       " 'dtype': 'float32',\n",
       " 'interpolation_order': 1,\n",
       " 'data_format': 'channels_last',\n",
       " 'channel_axis': 3,\n",
       " 'row_axis': 1,\n",
       " 'col_axis': 2,\n",
       " '_validation_split': 0.0,\n",
       " 'mean': None,\n",
       " 'std': None,\n",
       " 'principal_components': None,\n",
       " 'brightness_range': None}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "Unable to allocate array with shape (50000, 32, 32, 3) and data type float32",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-40-2fa13638e952>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[1;31m# 특정기능은 fit을 해줘야 실행되기 때문에 필요한 것이다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      2\u001b[0m \u001b[1;31m# zca_whitening 같은 옵션은 fit을 해줘야 실행된다.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 3\u001b[1;33m \u001b[0mdatagen\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx_train\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\AppData\\Roaming\\Python\\Python37\\site-packages\\keras_preprocessing\\image\\image_data_generator.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, x, augment, rounds, seed)\u001b[0m\n\u001b[0;32m    943\u001b[0m             \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrandom\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mseed\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    944\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 945\u001b[1;33m         \u001b[0mx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcopy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    946\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0maugment\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    947\u001b[0m             ax = np.zeros(\n",
      "\u001b[1;32m<__array_function__ internals>\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(*args, **kwargs)\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\lib\\function_base.py\u001b[0m in \u001b[0;36mcopy\u001b[1;34m(a, order)\u001b[0m\n\u001b[0;32m    788\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    789\u001b[0m     \"\"\"\n\u001b[1;32m--> 790\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0morder\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0morder\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcopy\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    791\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    792\u001b[0m \u001b[1;31m# Basic operations\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mMemoryError\u001b[0m: Unable to allocate array with shape (50000, 32, 32, 3) and data type float32"
     ]
    }
   ],
   "source": [
    "# 특정기능은 fit을 해줘야 실행되기 때문에 필요한 것이다. \n",
    "# zca_whitening 같은 옵션은 fit을 해줘야 실행된다.\n",
    "datagen.fit(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'featurewise_center': False,\n",
       " 'samplewise_center': False,\n",
       " 'featurewise_std_normalization': False,\n",
       " 'samplewise_std_normalization': False,\n",
       " 'zca_whitening': False,\n",
       " 'zca_epsilon': 1e-06,\n",
       " 'rotation_range': 0,\n",
       " 'width_shift_range': 0.1,\n",
       " 'height_shift_range': 0.1,\n",
       " 'shear_range': 0.0,\n",
       " 'zoom_range': [1.0, 1.0],\n",
       " 'channel_shift_range': 0.0,\n",
       " 'fill_mode': 'nearest',\n",
       " 'cval': 0.0,\n",
       " 'horizontal_flip': True,\n",
       " 'vertical_flip': False,\n",
       " 'rescale': None,\n",
       " 'preprocessing_function': None,\n",
       " 'dtype': 'float32',\n",
       " 'interpolation_order': 1,\n",
       " 'data_format': 'channels_last',\n",
       " 'channel_axis': 3,\n",
       " 'row_axis': 1,\n",
       " 'col_axis': 2,\n",
       " '_validation_split': 0.0,\n",
       " 'mean': None,\n",
       " 'std': None,\n",
       " 'principal_components': None,\n",
       " 'brightness_range': None}"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vars(datagen)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__le__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_validation_split',\n",
       " 'apply_transform',\n",
       " 'brightness_range',\n",
       " 'channel_axis',\n",
       " 'channel_shift_range',\n",
       " 'col_axis',\n",
       " 'cval',\n",
       " 'data_format',\n",
       " 'dtype',\n",
       " 'featurewise_center',\n",
       " 'featurewise_std_normalization',\n",
       " 'fill_mode',\n",
       " 'fit',\n",
       " 'flow',\n",
       " 'flow_from_dataframe',\n",
       " 'flow_from_directory',\n",
       " 'get_random_transform',\n",
       " 'height_shift_range',\n",
       " 'horizontal_flip',\n",
       " 'interpolation_order',\n",
       " 'mean',\n",
       " 'preprocessing_function',\n",
       " 'principal_components',\n",
       " 'random_transform',\n",
       " 'rescale',\n",
       " 'rotation_range',\n",
       " 'row_axis',\n",
       " 'samplewise_center',\n",
       " 'samplewise_std_normalization',\n",
       " 'shear_range',\n",
       " 'standardize',\n",
       " 'std',\n",
       " 'vertical_flip',\n",
       " 'width_shift_range',\n",
       " 'zca_epsilon',\n",
       " 'zca_whitening',\n",
       " 'zoom_range']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datagen)\n",
    "# next가 없으므로 이건 generator가 아니다. \n",
    "# flow를 해야지만 generator로 바꿀 수 있다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "collapsed": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['__class__',\n",
       " '__delattr__',\n",
       " '__dict__',\n",
       " '__dir__',\n",
       " '__doc__',\n",
       " '__eq__',\n",
       " '__format__',\n",
       " '__ge__',\n",
       " '__getattribute__',\n",
       " '__getitem__',\n",
       " '__gt__',\n",
       " '__hash__',\n",
       " '__init__',\n",
       " '__init_subclass__',\n",
       " '__iter__',\n",
       " '__le__',\n",
       " '__len__',\n",
       " '__lt__',\n",
       " '__module__',\n",
       " '__ne__',\n",
       " '__new__',\n",
       " '__next__',\n",
       " '__reduce__',\n",
       " '__reduce_ex__',\n",
       " '__repr__',\n",
       " '__setattr__',\n",
       " '__sizeof__',\n",
       " '__str__',\n",
       " '__subclasshook__',\n",
       " '__weakref__',\n",
       " '_flow_index',\n",
       " '_get_batches_of_transformed_samples',\n",
       " '_keras_api_names',\n",
       " '_keras_api_names_v1',\n",
       " '_set_index_array',\n",
       " 'batch_index',\n",
       " 'batch_size',\n",
       " 'data_format',\n",
       " 'dtype',\n",
       " 'image_data_generator',\n",
       " 'index_array',\n",
       " 'index_generator',\n",
       " 'lock',\n",
       " 'n',\n",
       " 'next',\n",
       " 'on_epoch_end',\n",
       " 'reset',\n",
       " 'sample_weight',\n",
       " 'save_format',\n",
       " 'save_prefix',\n",
       " 'save_to_dir',\n",
       " 'seed',\n",
       " 'shuffle',\n",
       " 'total_batches_seen',\n",
       " 'white_list_formats',\n",
       " 'x',\n",
       " 'x_misc',\n",
       " 'y']"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dir(datagen.flow(x_train,y_train))\n",
    "# generator가 된다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "# flow: generator로 만들어준다. \n",
    "# ImageDataGenerator.flow_from_dataframe\n",
    "# datagen.flow_from_directory \n",
    "# datagen.flow\n",
    "# Imagedata.fit_generator() : Next가 되기 때문에 generator를 써야한다. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 130/1563 [=>............................] - ETA: 10:59 - loss: 2.4090 - accuracy: 0.0971"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-45-8f536e0c508a>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      2\u001b[0m                                      batch_size=batch_size),\n\u001b[0;32m      3\u001b[0m                         \u001b[0mepochs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mepochs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;31m# epoch 당 generator 몇개 보낼지\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 4\u001b[1;33m                         validation_data=(x_test, y_test))\n\u001b[0m\u001b[0;32m      5\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;31m# workers = n_jobs: 동시에 4개 실행 (일하는 놈: 4놈)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mfit_generator\u001b[1;34m(self, generator, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch)\u001b[0m\n\u001b[0;32m   1295\u001b[0m         \u001b[0mshuffle\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mshuffle\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1296\u001b[0m         \u001b[0minitial_epoch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1297\u001b[1;33m         steps_name='steps_per_epoch')\n\u001b[0m\u001b[0;32m   1298\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1299\u001b[0m   def evaluate_generator(self,\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_generator.py\u001b[0m in \u001b[0;36mmodel_iteration\u001b[1;34m(model, data, steps_per_epoch, epochs, verbose, callbacks, validation_data, validation_steps, validation_freq, class_weight, max_queue_size, workers, use_multiprocessing, shuffle, initial_epoch, mode, batch_size, steps_name, **kwargs)\u001b[0m\n\u001b[0;32m    263\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    264\u001b[0m       \u001b[0mis_deferred\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_is_compiled\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 265\u001b[1;33m       \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch_function\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mbatch_data\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    266\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    267\u001b[0m         \u001b[0mbatch_outs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mbatch_outs\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(self, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    971\u001b[0m       outputs = training_v2_utils.train_on_batch(\n\u001b[0;32m    972\u001b[0m           \u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 973\u001b[1;33m           class_weight=class_weight, reset_metrics=reset_metrics)\n\u001b[0m\u001b[0;32m    974\u001b[0m       outputs = (outputs['total_loss'] + outputs['output_losses'] +\n\u001b[0;32m    975\u001b[0m                  outputs['metrics'])\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_v2_utils.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, x, y, sample_weight, class_weight, reset_metrics)\u001b[0m\n\u001b[0;32m    262\u001b[0m       \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    263\u001b[0m       \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 264\u001b[1;33m       output_loss_metrics=model._output_loss_metrics)\n\u001b[0m\u001b[0;32m    265\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mreset_metrics\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36mtrain_on_batch\u001b[1;34m(model, inputs, targets, sample_weights, output_loss_metrics)\u001b[0m\n\u001b[0;32m    309\u001b[0m           \u001b[0msample_weights\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0msample_weights\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    310\u001b[0m           \u001b[0mtraining\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mTrue\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 311\u001b[1;33m           output_loss_metrics=output_loss_metrics))\n\u001b[0m\u001b[0;32m    312\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    313\u001b[0m     \u001b[0mouts\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m[\u001b[0m\u001b[0mouts\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\engine\\training_eager.py\u001b[0m in \u001b[0;36m_process_single_batch\u001b[1;34m(model, inputs, targets, output_loss_metrics, sample_weights, training)\u001b[0m\n\u001b[0;32m    270\u001b[0m                         loss_scale_optimizer.LossScaleOptimizer):\n\u001b[0;32m    271\u001b[0m             \u001b[0mgrads\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mget_unscaled_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 272\u001b[1;33m           \u001b[0mmodel\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0moptimizer\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_gradients\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mzip\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrainable_weights\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    273\u001b[0m       \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    274\u001b[0m         logging.warning('The list of trainable weights is empty. Make sure that'\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_gradients\u001b[1;34m(self, grads_and_vars, name)\u001b[0m\n\u001b[0;32m    439\u001b[0m           \u001b[0mfunctools\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpartial\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_distributed_apply\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    440\u001b[0m           \u001b[0margs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 441\u001b[1;33m           kwargs={\"name\": name})\n\u001b[0m\u001b[0;32m    442\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    443\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_distributed_apply\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistribution\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgrads_and_vars\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mmerge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1915\u001b[0m     \u001b[1;32mif\u001b[0m \u001b[0mkwargs\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1916\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1917\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1918\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1919\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_merge_call\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_merge_call\u001b[1;34m(self, merge_fn, args, kwargs)\u001b[0m\n\u001b[0;32m   1922\u001b[0m         distribution_strategy_context._CrossReplicaThreadMode(self._strategy))  # pylint: disable=protected-access\n\u001b[0;32m   1923\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1924\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mmerge_fn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_strategy\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1925\u001b[0m     \u001b[1;32mfinally\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1926\u001b[0m       \u001b[0m_pop_per_thread_mode\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36m_distributed_apply\u001b[1;34m(self, distribution, grads_and_vars, name, apply_state)\u001b[0m\n\u001b[0;32m    483\u001b[0m           update_ops.extend(\n\u001b[0;32m    484\u001b[0m               distribution.extended.update(\n\u001b[1;32m--> 485\u001b[1;33m                   var, apply_grad_to_update_var, args=(grad,), group=False))\n\u001b[0m\u001b[0;32m    486\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    487\u001b[0m       any_symbolic = any(isinstance(i, ops.Operation) or\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36mupdate\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   1528\u001b[0m       \u001b[0mkwargs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;33m{\u001b[0m\u001b[1;33m}\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1529\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_container_strategy\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mscope\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1530\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1531\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1532\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update\u001b[1;34m(self, var, fn, args, kwargs, group)\u001b[0m\n\u001b[0;32m   2140\u001b[0m     \u001b[1;31m# The implementations of _update() and _update_non_slot() are identical\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2141\u001b[0m     \u001b[1;31m# except _update() passes `var` as the first argument to `fn()`.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2142\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m+\u001b[0m \u001b[0mtuple\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mgroup\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2143\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2144\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0m_update_non_slot\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcolocate_with\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mkwargs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\distribute\\distribute_lib.py\u001b[0m in \u001b[0;36m_update_non_slot\u001b[1;34m(self, colocate_with, fn, args, kwargs, should_group)\u001b[0m\n\u001b[0;32m   2146\u001b[0m     \u001b[1;31m# once that value is used for something.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2147\u001b[0m     \u001b[1;32mwith\u001b[0m \u001b[0mUpdateContext\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mcolocate_with\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 2148\u001b[1;33m       \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mfn\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   2149\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mshould_group\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   2150\u001b[0m         \u001b[1;32mreturn\u001b[0m \u001b[0mresult\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\optimizer_v2.py\u001b[0m in \u001b[0;36mapply_grad_to_update_var\u001b[1;34m(var, grad)\u001b[0m\n\u001b[0;32m    465\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[1;34m\"apply_state\"\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dense_apply_args\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    466\u001b[0m         \u001b[0mapply_kwargs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;34m\"apply_state\"\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mapply_state\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 467\u001b[1;33m       \u001b[0mupdate_op\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_resource_apply_dense\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mgrad\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mapply_kwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    468\u001b[0m       \u001b[1;32mif\u001b[0m \u001b[0mvar\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconstraint\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    469\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcontrol_dependencies\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mupdate_op\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\keras\\optimizer_v2\\rmsprop.py\u001b[0m in \u001b[0;36m_resource_apply_dense\u001b[1;34m(self, grad, var, apply_state)\u001b[0m\n\u001b[0;32m    174\u001b[0m             use_locking=self._use_locking)\n\u001b[0;32m    175\u001b[0m     \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 176\u001b[1;33m       rms_t = (coefficients[\"rho\"] * rms +\n\u001b[0m\u001b[0;32m    177\u001b[0m                coefficients[\"one_minus_rho\"] * math_ops.square(grad))\n\u001b[0;32m    178\u001b[0m       \u001b[0mrms_t\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstate_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0massign\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mrms\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrms_t\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0muse_locking\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_use_locking\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36mbinary_op_wrapper\u001b[1;34m(x, y)\u001b[0m\n\u001b[0;32m    910\u001b[0m           \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    911\u001b[0m             \u001b[1;32mraise\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 912\u001b[1;33m       \u001b[1;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    913\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    914\u001b[0m   \u001b[1;32mdef\u001b[0m \u001b[0mbinary_op_wrapper_sparse\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msp_x\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\math_ops.py\u001b[0m in \u001b[0;36m_mul_dispatch\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   1204\u001b[0m   \u001b[0mis_tensor_y\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mTensor\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1205\u001b[0m   \u001b[1;32mif\u001b[0m \u001b[0mis_tensor_y\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1206\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0mgen_math_ops\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmul\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mname\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mname\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1207\u001b[0m   \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1208\u001b[0m     \u001b[1;32massert\u001b[0m \u001b[0misinstance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msparse_tensor\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mSparseTensor\u001b[0m\u001b[1;33m)\u001b[0m  \u001b[1;31m# Case: Dense * Sparse.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\tensorflow_core\\python\\ops\\gen_math_ops.py\u001b[0m in \u001b[0;36mmul\u001b[1;34m(x, y, name)\u001b[0m\n\u001b[0;32m   6682\u001b[0m       _result = _pywrap_tensorflow.TFE_Py_FastPathExecute(\n\u001b[0;32m   6683\u001b[0m         \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_context_handle\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0m_ctx\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_thread_local_data\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdevice_name\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m\"Mul\"\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 6684\u001b[1;33m         name, _ctx._post_execution_callbacks, x, y)\n\u001b[0m\u001b[0;32m   6685\u001b[0m       \u001b[1;32mreturn\u001b[0m \u001b[0m_result\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   6686\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0m_core\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_FallbackException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit_generator(datagen.flow(x_train, y_train,\n",
    "                                     batch_size=batch_size),\n",
    "                        epochs=epochs, # epoch 당 generator 몇개 보낼지\n",
    "                        validation_data=(x_test, y_test))\n",
    "\n",
    "# workers = n_jobs: 동시에 4개 실행 (일하는 놈: 4놈)\n",
    "# 전처리까지 하기 때문에 속도가 훨씬 느리다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "이미지 데이터 제너레이터는 옵션을 관할하고\n",
    "flow가 제너레이터로 바꿔준다. \n",
    "flow로 바꿔주고, fit_generator로 학습시킨다.\n",
    "이미지데이터제너레이터는 fit_generator를 써야한다. \n",
    "\n",
    "- 하나 만들어 놓으면 다른 애들 추가시키고, 차후 변경시킬 때 편하다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "cnn은 성능이 좋은 반면 느리다. \n",
    "1. train slow \n",
    "2. better performance "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model and weights\n",
    "# if not os.path.isdir(save_dir):\n",
    "#     os.makedirs(save_dir)\n",
    "# model_path = os.path.join(save_dir, model_name)\n",
    "# model.save(model_path)\n",
    "# print('Saved trained model at %s ' % model_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Score trained model.\n",
    "scores = model.evaluate(x_test, y_test, verbose=1)\n",
    "print('Test loss:', scores[0])\n",
    "print('Test accuracy:', scores[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tensorflow board\n",
    "\n",
    "load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "application/json": {
       "cell": {
        "!": "OSMagics",
        "HTML": "Other",
        "SVG": "Other",
        "bash": "Other",
        "capture": "ExecutionMagics",
        "cmd": "Other",
        "debug": "ExecutionMagics",
        "file": "Other",
        "html": "DisplayMagics",
        "javascript": "DisplayMagics",
        "js": "DisplayMagics",
        "latex": "DisplayMagics",
        "markdown": "DisplayMagics",
        "perl": "Other",
        "prun": "ExecutionMagics",
        "pypy": "Other",
        "python": "Other",
        "python2": "Other",
        "python3": "Other",
        "ruby": "Other",
        "script": "ScriptMagics",
        "sh": "Other",
        "svg": "DisplayMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "writefile": "OSMagics"
       },
       "line": {
        "alias": "OSMagics",
        "alias_magic": "BasicMagics",
        "autoawait": "AsyncMagics",
        "autocall": "AutoMagics",
        "automagic": "AutoMagics",
        "autosave": "KernelMagics",
        "bookmark": "OSMagics",
        "cd": "OSMagics",
        "clear": "KernelMagics",
        "cls": "KernelMagics",
        "colors": "BasicMagics",
        "conda": "PackagingMagics",
        "config": "ConfigMagics",
        "connect_info": "KernelMagics",
        "copy": "Other",
        "ddir": "Other",
        "debug": "ExecutionMagics",
        "dhist": "OSMagics",
        "dirs": "OSMagics",
        "doctest_mode": "BasicMagics",
        "echo": "Other",
        "ed": "Other",
        "edit": "KernelMagics",
        "env": "OSMagics",
        "gui": "BasicMagics",
        "hist": "Other",
        "history": "HistoryMagics",
        "killbgscripts": "ScriptMagics",
        "ldir": "Other",
        "less": "KernelMagics",
        "load": "CodeMagics",
        "load_ext": "ExtensionMagics",
        "loadpy": "CodeMagics",
        "logoff": "LoggingMagics",
        "logon": "LoggingMagics",
        "logstart": "LoggingMagics",
        "logstate": "LoggingMagics",
        "logstop": "LoggingMagics",
        "ls": "Other",
        "lsmagic": "BasicMagics",
        "macro": "ExecutionMagics",
        "magic": "BasicMagics",
        "matplotlib": "PylabMagics",
        "mkdir": "Other",
        "more": "KernelMagics",
        "notebook": "BasicMagics",
        "page": "BasicMagics",
        "pastebin": "CodeMagics",
        "pdb": "ExecutionMagics",
        "pdef": "NamespaceMagics",
        "pdoc": "NamespaceMagics",
        "pfile": "NamespaceMagics",
        "pinfo": "NamespaceMagics",
        "pinfo2": "NamespaceMagics",
        "pip": "PackagingMagics",
        "popd": "OSMagics",
        "pprint": "BasicMagics",
        "precision": "BasicMagics",
        "prun": "ExecutionMagics",
        "psearch": "NamespaceMagics",
        "psource": "NamespaceMagics",
        "pushd": "OSMagics",
        "pwd": "OSMagics",
        "pycat": "OSMagics",
        "pylab": "PylabMagics",
        "qtconsole": "KernelMagics",
        "quickref": "BasicMagics",
        "recall": "HistoryMagics",
        "rehashx": "OSMagics",
        "reload_ext": "ExtensionMagics",
        "ren": "Other",
        "rep": "Other",
        "rerun": "HistoryMagics",
        "reset": "NamespaceMagics",
        "reset_selective": "NamespaceMagics",
        "rmdir": "Other",
        "run": "ExecutionMagics",
        "save": "CodeMagics",
        "sc": "OSMagics",
        "set_env": "OSMagics",
        "store": "StoreMagics",
        "sx": "OSMagics",
        "system": "OSMagics",
        "tb": "ExecutionMagics",
        "tensorboard": "Other",
        "time": "ExecutionMagics",
        "timeit": "ExecutionMagics",
        "unalias": "OSMagics",
        "unload_ext": "ExtensionMagics",
        "who": "NamespaceMagics",
        "who_ls": "NamespaceMagics",
        "whos": "NamespaceMagics",
        "xdel": "NamespaceMagics",
        "xmode": "BasicMagics"
       }
      },
      "text/plain": [
       "Available line magics:\n",
       "%alias  %alias_magic  %autoawait  %autocall  %automagic  %autosave  %bookmark  %cd  %clear  %cls  %colors  %conda  %config  %connect_info  %copy  %ddir  %debug  %dhist  %dirs  %doctest_mode  %echo  %ed  %edit  %env  %gui  %hist  %history  %killbgscripts  %ldir  %less  %load  %load_ext  %loadpy  %logoff  %logon  %logstart  %logstate  %logstop  %ls  %lsmagic  %macro  %magic  %matplotlib  %mkdir  %more  %notebook  %page  %pastebin  %pdb  %pdef  %pdoc  %pfile  %pinfo  %pinfo2  %pip  %popd  %pprint  %precision  %prun  %psearch  %psource  %pushd  %pwd  %pycat  %pylab  %qtconsole  %quickref  %recall  %rehashx  %reload_ext  %ren  %rep  %rerun  %reset  %reset_selective  %rmdir  %run  %save  %sc  %set_env  %store  %sx  %system  %tb  %tensorboard  %time  %timeit  %unalias  %unload_ext  %who  %who_ls  %whos  %xdel  %xmode\n",
       "\n",
       "Available cell magics:\n",
       "%%!  %%HTML  %%SVG  %%bash  %%capture  %%cmd  %%debug  %%file  %%html  %%javascript  %%js  %%latex  %%markdown  %%perl  %%prun  %%pypy  %%python  %%python2  %%python3  %%ruby  %%script  %%sh  %%svg  %%sx  %%system  %%time  %%timeit  %%writefile\n",
       "\n",
       "Automagic is ON, % prefix IS NOT needed for line magics."
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 현재 %로 쓸 수 있는 애들 \n",
    "%lsmagic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%tensorboard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "2 + 5 + 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "11"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "11"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
